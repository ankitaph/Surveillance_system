{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1O1DsOwsCwMT"
      },
      "source": [
        "# New section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "psqUM3tIIdJo"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install ultralytics\n",
        "!pip install deep-sort-realtime opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kCEOVy7eKBWE",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
        "from google.colab.patches import cv2_imshow  # <-- Needed for Colab\n",
        "\n",
        "# ============================\n",
        "# LOAD YOUR YOLO PERSON MODEL\n",
        "# ============================\n",
        "\n",
        "PERSON_MODEL_PATH = \"/content/drive/MyDrive/person detection/yolov8n.pt\"\n",
        "person_model = YOLO(PERSON_MODEL_PATH)\n",
        "\n",
        "# ============================\n",
        "# INITIALIZE DeepSORT\n",
        "# ============================\n",
        "\n",
        "tracker = DeepSort(\n",
        "    max_age=25,\n",
        "    n_init=2,\n",
        "    max_iou_distance=0.7,\n",
        "    embedder=\"mobilenet\",\n",
        "    half=True,\n",
        ")\n",
        "\n",
        "# ============================\n",
        "# PROCESS INPUT VIDEO\n",
        "# ============================\n",
        "\n",
        "input_video_path = \"/content/drive/MyDrive/person detection/PETS09-S2L2-raw.mp4\"\n",
        "output_video_path = \"/content/drive/MyDrive/person detection/2_output_tracked.mp4\"\n",
        "\n",
        "cap = cv2.VideoCapture(input_video_path)\n",
        "\n",
        "w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "out = cv2.VideoWriter(output_video_path, fourcc, fps, (w, h))\n",
        "\n",
        "print(\"Processing...\")\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # ============================\n",
        "    # YOLO INFERENCE\n",
        "    # ============================\n",
        "    results = person_model(frame, conf=0.45)[0]\n",
        "\n",
        "    detections = []\n",
        "\n",
        "    for box in results.boxes:\n",
        "        cls_id = int(box.cls[0].item())  # FIXED\n",
        "        label = person_model.names[cls_id]\n",
        "\n",
        "        if label != \"person\":\n",
        "            continue\n",
        "\n",
        "        x1, y1, x2, y2 = box.xyxy[0].tolist()  # FIXED\n",
        "        conf = float(box.conf[0].item())      # FIXED\n",
        "\n",
        "        detections.append(([x1, y1, x2 - x1, y2 - y1], conf, label))\n",
        "\n",
        "    # ============================\n",
        "    # DeepSORT TRACKING\n",
        "    # ============================\n",
        "    tracks = tracker.update_tracks(detections, frame=frame)\n",
        "\n",
        "    # ============================\n",
        "    # DRAW RESULTS\n",
        "    # ============================\n",
        "\n",
        "    for track in tracks:\n",
        "        if not track.is_confirmed():\n",
        "            continue\n",
        "\n",
        "        track_id = track.track_id\n",
        "        x1, y1, x2, y2 = map(int, track.to_ltrb())\n",
        "\n",
        "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "        cv2.putText(frame, f\"ID: {track_id}\", (x1, y1 - 10),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
        "\n",
        "    # ============================\n",
        "    # SHOW REAL-TIME OUTPUT (Colab)\n",
        "    # ============================\n",
        "    cv2_imshow(frame)  # <-- This works in Colab\n",
        "\n",
        "    out.write(frame)\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "\n",
        "print(\"Processing complete! File saved at:\", output_video_path)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}